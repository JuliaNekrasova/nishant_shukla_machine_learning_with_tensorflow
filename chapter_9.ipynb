{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names:  ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "data shape: (50000, 3072),  labels shape (50000,)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4820469128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f47ce5535f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "def unpickle(file):\n",
    "    fo = open(file, 'rb')\n",
    "    dict = pickle.load(fo, encoding='latin1')\n",
    "    fo.close()\n",
    "    return dict\n",
    "\n",
    "def show_some_examples(names, data, labels):\n",
    "    plt.figure()\n",
    "    rows, cols = 4,4\n",
    "    random_idxs = random.sample(range(len(data)), rows * cols)\n",
    "    for i in range(rows * cols):\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        j = random_idxs[i]\n",
    "        plt.title(names[labels[j]])\n",
    "        img = np.reshape(data[j, :], (24, 24))\n",
    "        plt.imshow(img, cmap='Greys_r')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig('cifar_examples.png')\n",
    "\n",
    "def clean(data):\n",
    "    imgs = data.reshape(data.shape[0], 3, 32, 32)\n",
    "    grayscale_imgs = imgs.mean(1)\n",
    "    cropped_imgs = grayscale_imgs[:, 4:28, 4:28]\n",
    "    img_data = cropped_imgs.reshape(data.shape[0], -1)\n",
    "    img_size = np.shape(img_data)[1]\n",
    "    means = np.mean(img_data, axis = 1)\n",
    "    meansT = means.reshape(len(means), 1)\n",
    "    stds = np.std(img_data, axis = 1)\n",
    "    stdsT = stds.reshape(len(stds), 1)\n",
    "    adj_stds = np.maximum(stdsT, 1.0 / np.sqrt(img_size))\n",
    "    normalized = (img_data - meansT) / adj_stds\n",
    "    return normalized\n",
    "\n",
    "def read_data():\n",
    "    names = unpickle('./data/cifar-10-batches-py/batches.meta')['label_names']\n",
    "    print('names: ', names)\n",
    "    \n",
    "    data, labels = [], []\n",
    "    for i in range(1, 6):\n",
    "        filename = './data/cifar-10-batches-py/data_batch_' + str(i)\n",
    "        batch_data = unpickle(filename)\n",
    "        if len(data) > 0:\n",
    "            data = np.vstack((data, batch_data['data']))\n",
    "            labels = np.hstack((labels, batch_data['labels']))\n",
    "        else:\n",
    "            data = batch_data['data']\n",
    "            labels = batch_data['labels']\n",
    "   \n",
    "    print('data shape: {},  labels shape {}'.format(np.shape(data), np.shape(labels)))\n",
    "    \n",
    "    data = clean(data)\n",
    "    data = data.astype(np.float32)\n",
    "    return names, data, labels\n",
    "\n",
    "names, data, labels = read_data()\n",
    "show_some_examples(names, data, labels)\n",
    "\n",
    "W = tf.Variable(tf.random.normal([5, 5, 1, 32]))\n",
    "\n",
    "def show_weights(W):\n",
    "    plt.figure()\n",
    "    rows, cols = 4, 8\n",
    "    for i in range(np.shape(W)[3]):\n",
    "        img = W[:, :, 0, i]\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        plt.imshow(img, cmap = 'Greys_r', interpolation='none')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "def show_conv_results(data):\n",
    "    plt.figure()\n",
    "    rows, cols = 4, 8\n",
    "    for i in range(np.shape(data)[3]):\n",
    "        img = data[0, :, :, i]\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        plt.imshow(img, cmap = 'Greys_r', interpolation='none')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    W_val = sess.run(W)\n",
    "    show_weights(W_val)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = data[4, :]\n",
    "raw_img = np.reshape(raw_data, (24, 24))\n",
    "plt.figure()\n",
    "plt.imshow(raw_img, cmap = 'Greys_r', interpolation='none')\n",
    "\n",
    "x = tf.reshape(raw_data, shape=[-1, 24, 24, 1])\n",
    "b = tf.Variable(tf.random.normal([32]))\n",
    "conv = tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "conv_with_b = tf.nn.bias_add(conv, b)\n",
    "conv_out = tf.nn.relu(conv_with_b)\n",
    "\n",
    "k = 2\n",
    "maxpool = tf.nn.max_pool(conv_out, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    conv_val = sess.run(conv)\n",
    "    show_conv_results(conv_val)\n",
    "    \n",
    "    conv_out_val = sess.run(conv_out)\n",
    "    show_conv_results(conv_out_val)\n",
    "    \n",
    "    maxpool_val = sess.run(maxpool)\n",
    "    show_conv_results(maxpool_val)\n",
    "    print(np.shape(maxpool_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names:  ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "data shape: (50000, 3072),  labels shape (50000,)\n",
      "batch size: 250\n",
      "49750 0.264\n",
      "49750 0.112\n",
      "49750 0.132\n",
      "49750 0.136\n",
      "49750 0.052\n"
     ]
    }
   ],
   "source": [
    "def conv_layer(x, W, b):\n",
    "    conv = tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    conv_with_b = tf.nn.bias_add(conv, b)\n",
    "    conv_out = tf.nn.relu(conv_with_b)\n",
    "    return conv_out\n",
    "\n",
    "def maxpool_layer(conv, k=2):\n",
    "    return tf.nn.max_pool(conv, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')\n",
    "    \n",
    "names, data, labels = read_data()\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 24 * 24])\n",
    "y = tf.placeholder(tf.float32, [None, len(names)])\n",
    "\n",
    "W1 = tf.Variable(tf.random.normal([5, 5, 1, 64]))\n",
    "b1 = tf.Variable(tf.random.normal([64]))\n",
    "\n",
    "W2 = tf.Variable(tf.random.normal([5, 5, 64, 64]))\n",
    "b2 = tf.Variable(tf.random.normal([64]))\n",
    "\n",
    "W3 = tf.Variable(tf.random.normal([6 * 6 * 64, 1024]))\n",
    "b3 = tf.Variable(tf.random.normal([1024]))\n",
    "\n",
    "W_out = tf.Variable(tf.random.normal([1024, len(names)]))\n",
    "b_out = tf.Variable(tf.random.normal([len(names)]))\n",
    "\n",
    "x_reshape = tf.reshape(x, shape=[-1, 24, 24, 1])\n",
    "\n",
    "conv_out1 = conv_layer(x_reshape, W1, b1)\n",
    "maxpool_out1 = maxpool_layer(conv_out1)\n",
    "norm1 = tf.nn.lrn(maxpool_out1, 4, bias=1.0, alpha=0.001/9.0, beta=0.75)\n",
    "\n",
    "conv_out2 = conv_layer(norm1, W2, b2)\n",
    "norm2 = tf.nn.lrn(maxpool_out1, 4, bias=1.0, alpha=0.001/9.0, beta=0.75)\n",
    "maxpool_out2 = maxpool_layer(conv_out2)\n",
    "\n",
    "maxpool_reshaped = tf.reshape(maxpool_out2, [-1, W3.get_shape().as_list()[0]])\n",
    "local = tf.add(tf.matmul(maxpool_reshaped, W3), b3)\n",
    "local_out = tf.nn.relu(local)\n",
    "\n",
    "model_op = tf.add(tf.matmul(local_out, W_out), b_out)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model_op, labels=y))\n",
    "\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(model_op, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    onehot_labels = tf.one_hot(labels, len(names), on_value=1., off_value=0., axis=-1)\n",
    "    onehot_vals = sess.run(onehot_labels)\n",
    "    batch_size = len(data) // 200\n",
    "    print('batch size:', batch_size)\n",
    "    for j in range(0, 100):\n",
    "        for i in range(0, len(data), batch_size):\n",
    "            batch_data = data[i:i + batch_size, :]\n",
    "            batch_onehot_vals = onehot_vals[i:i + batch_size, :]\n",
    "            _, accuracy_val = sess.run([train_op, accuracy], feed_dict={x: batch_data, y:batch_onehot_vals})\n",
    "        if j % 10 == 0:\n",
    "            print(j, accuracy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
